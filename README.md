# PyTorch MNIST CNN Learning Project

A clean, educational PyTorch implementation for MNIST digit classification using Convolutional Neural Networks.

## ğŸ¯ Project Overview

This project demonstrates fundamental PyTorch concepts through a well-structured CNN that achieves **99.37% accuracy** on MNIST digit recognition.

## ğŸ“ Project Structure

```
pytorch_learn/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ .gitignore               # Git ignore rules
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ mnist_handler.py     # Optimized MNIST data loading
â”‚   â””â”€â”€ mnist_cnn.py         # Complete CNN implementation
â”œâ”€â”€ data/
â”‚   â””â”€â”€ MNIST/               # Dataset (auto-downloaded)
â”œâ”€â”€ mnist_cnn.pth           # Trained model weights
â””â”€â”€ training_history.png    # Training visualization
```

## ğŸš€ Quick Start

1. **Setup Environment**
   ```bash
   conda create -n pytorch_learn_env python=3.8
   conda activate pytorch_learn_env
   conda install pytorch torchvision matplotlib
   ```

2. **Train the Model**
   ```bash
   python src/mnist_cnn.py
   ```

3. **Results**
   - Model trains for 10 epochs (~6 minutes on CPU)
   - Achieves 99.37% test accuracy
   - Saves trained model as `mnist_cnn.pth`
   - Generates training history visualization

## ğŸ§  What You'll Learn

- **CNN Architecture**: 3 convolutional layers + 2 fully connected layers
- **PyTorch Fundamentals**: Tensors, autograd, nn.Module, DataLoader
- **Training Loop**: Forward pass, loss calculation, backpropagation
- **Model Evaluation**: Accuracy metrics and visualization
- **Data Handling**: Efficient dataset loading and preprocessing

## ğŸ“Š Model Performance

- **Test Accuracy**: 99.37%
- **Parameters**: 688,138
- **Architecture**: Conv2D â†’ ReLU â†’ MaxPool â†’ Dropout â†’ FC
- **Training Time**: ~6 minutes (CPU)

## ğŸ”§ Technical Details

### CNN Architecture
```
Input (28x28) â†’ Conv(32) â†’ Conv(64) â†’ Conv(128) â†’ FC(512) â†’ FC(10)
```

### Key Features
- Dropout regularization (25% and 50%)
- Adam optimizer with learning rate 0.001
- Cross-entropy loss function
- Automatic device detection (CPU/GPU)

## ğŸ“ˆ Training Progress

The model shows consistent improvement:
- Epoch 1: 98.45% â†’ Epoch 10: 99.37%
- Training loss decreases steadily
- No overfitting observed

## ğŸ“ Learning Outcomes

This project covers essential PyTorch concepts:
- Building custom neural networks with `nn.Module`
- Implementing training and evaluation loops
- Using `DataLoader` for efficient batch processing
- Visualizing training progress with matplotlib
- Saving and loading model checkpoints

Perfect for beginners learning deep learning with PyTorch!